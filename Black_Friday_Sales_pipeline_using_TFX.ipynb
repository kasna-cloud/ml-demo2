{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "4. Preprocessing Pipeline\n",
        "The partner must:\n",
        "describe the data preprocessing pipeline, and \n",
        "how this is accomplished via a package/function that is a callable API (that is ultimately accessed by the served, production model).\n",
        "\n",
        "Evidence must include a description (in the Whitepaper) of how data preprocessing is accomplished, along with the code snippet that accomplishes data preprocessing as a callable API.\n",
        "```"
      ],
      "metadata": {
        "id": "q1BH5vnm4W6W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1ypzczQCwy"
      },
      "source": [
        "# Deploy model using TFX Pipeline\n",
        "To deploy the model we will following GCP best practises and use TensorFlow Extended (TFX). A TensorFlow pipeline is a sequence of components taht impoement an ML Pipeline which is specificially designed for scale, deployment, and retraining.\n",
        "\n",
        "To successfully deploy the model we will need address the 3 phases of the pipeline:\n",
        "1. Ingest & Validate Data\n",
        "  - ExampleGen\n",
        "  - StatisticsGen\n",
        "  - SchemaGen\n",
        "  - ExampleValidator\n",
        "2. Train & Analyze Model\n",
        "  - Transform\n",
        "  - Trainer\n",
        "3. Deploy in Production\n",
        "  - Pusher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC9W_S-bONgl"
      },
      "source": [
        "### Install python packages\n",
        "We will install required Python packages including TFX and KFP to author ML pipelines and submit jobs to Vertex Pipelines. We will be deploying the TFX pipeline onto the Apache Beam orchistrator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQtljP-qPHY",
        "outputId": "8a87f212-7215-410d-dcd3-d12a2fb5eed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.0.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tfx[kfp]<2 in /usr/local/lib/python3.7/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.21.5)\n",
            "Requirement already satisfied: google-cloud-bigquery<3,>=2.26.0 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (2.34.2)\n",
            "Requirement already satisfied: pyyaml<6,>=3.12 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (5.4.1)\n",
            "Requirement already satisfied: kubernetes<13,>=10.0.1 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (12.0.1)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<3,>=1.15 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (2.8.0)\n",
            "Requirement already satisfied: pyarrow<6,>=1 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (5.0.0)\n",
            "Collecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5\n",
            "  Using cached tensorflow-2.7.1-cp37-cp37m-manylinux2010_x86_64.whl (495.0 MB)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.8 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.12.10)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (0.12.0)\n",
            "Collecting tfx-bsl<1.7.0,>=1.6.0\n",
            "  Using cached tfx_bsl-1.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (19.1 MB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.11.0)\n",
            "Requirement already satisfied: attrs<21,>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (20.3.0)\n",
            "Requirement already satisfied: ml-pipelines-sdk==1.6.1 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.6.1)\n",
            "Requirement already satisfied: click<8,>=7 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (7.1.2)\n",
            "Requirement already satisfied: ml-metadata<1.7.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.6.0)\n",
            "Collecting tensorflow-transform<1.7.0,>=1.6.0\n",
            "  Using cached tensorflow_transform-1.6.0-py3-none-any.whl (427 kB)\n",
            "Requirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.3.9)\n",
            "Requirement already satisfied: google-apitools<1,>=0.5 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (0.5.31)\n",
            "Requirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (2.11.3)\n",
            "Requirement already satisfied: packaging<21,>=20 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (20.9)\n",
            "Requirement already satisfied: docker<5,>=4.1 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (4.4.4)\n",
            "Requirement already satisfied: tensorflow-data-validation<1.7.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.6.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (3.19.4)\n",
            "Requirement already satisfied: tensorflow-model-analysis<0.38,>=0.37.0 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (0.37.0)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.35 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (2.37.0)\n",
            "Requirement already satisfied: keras-tuner<2,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.1.0)\n",
            "Requirement already satisfied: kfp<2,>=1.8.5 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (1.8.11)\n",
            "Requirement already satisfied: kfp-pipeline-spec<0.2,>=0.1.10 in /usr/local/lib/python3.7/dist-packages (from tfx[kfp]<2) (0.1.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py<2.0.0,>=0.9->tfx[kfp]<2) (1.15.0)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.17.4)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.3.1.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (3.10.0.2)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.0.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.7)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (3.6.7)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2021.3)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.20.3)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.6.0)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.4.10)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.27.1)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (4.1.3)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (3.12.3)\n",
            "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.0.0)\n",
            "Requirement already satisfied: google-cloud-spanner<2,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.19.1)\n",
            "Requirement already satisfied: cachetools<5,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (4.2.4)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (3.6.2)\n",
            "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.7.0)\n",
            "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.3.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.35.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage>=2.6.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.12.0)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<=0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.2.0)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.10.0)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.4.1)\n",
            "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.16.1)\n",
            "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.7.2)\n",
            "Requirement already satisfied: grpcio-gcp<1,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.2.2)\n",
            "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.8.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker<5,>=4.1->tfx[kfp]<2) (1.3.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->tfx[kfp]<2) (1.31.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->tfx[kfp]<2) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->tfx[kfp]<2) (0.0.4)\n",
            "Requirement already satisfied: fasteners>=0.14 in /usr/local/lib/python3.7/dist-packages (from google-apitools<1,>=0.5->tfx[kfp]<2) (0.17.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform<2,>=1.5.0->tfx[kfp]<2) (1.44.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3,>=2.26.0->tfx[kfp]<2) (2.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<4,>=2.7.3->tfx[kfp]<2) (2.0.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2,>=1.0.4->tfx[kfp]<2) (7.32.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2,>=1.0.4->tfx[kfp]<2) (1.0.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2,>=1.0.4->tfx[kfp]<2) (2.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2,>=1.0.4->tfx[kfp]<2) (1.4.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (0.13)\n",
            "Requirement already satisfied: typer<1.0,>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (0.4.0)\n",
            "Requirement already satisfied: Deprecated<2,>=1.2.7 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (1.2.13)\n",
            "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (1.8.1)\n",
            "Requirement already satisfied: fire<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (0.4.0)\n",
            "Requirement already satisfied: strip-hints<1,>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (0.1.10)\n",
            "Requirement already satisfied: jsonschema<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (3.2.0)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (0.9.1)\n",
            "Requirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.7/dist-packages (from kfp<2,>=1.8.5->tfx[kfp]<2) (0.8.9)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from kubernetes<13,>=10.0.1->tfx[kfp]<2) (1.3.1)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from kubernetes<13,>=10.0.1->tfx[kfp]<2) (57.4.0)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.7/dist-packages (from kubernetes<13,>=10.0.1->tfx[kfp]<2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.7/dist-packages (from kubernetes<13,>=10.0.1->tfx[kfp]<2) (2021.10.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<21,>=20->tfx[kfp]<2) (3.0.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (13.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (1.13.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (3.3.0)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (0.24.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (1.1.2)\n",
            "Requirement already satisfied: joblib<0.15,>=0.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-data-validation<1.7.0,>=1.6.0->tfx[kfp]<2) (0.14.1)\n",
            "Collecting tensorflow-metadata<1.7,>=1.6.0\n",
            "  Using cached tensorflow_metadata-1.6.0-py3-none-any.whl (48 kB)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-data-validation<1.7.0,>=1.6.0->tfx[kfp]<2) (1.3.5)\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (7.6.5)\n",
            "Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<3,>=1.15\n",
            "  Using cached tensorflow_serving_api-2.7.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.8->tfx[kfp]<2) (1.55.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (4.8)\n",
            "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.12.3)\n",
            "Requirement already satisfied: grpcio-status>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (1.44.0)\n",
            "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (6.1.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx[kfp]<2) (1.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5->tfx[kfp]<2) (1.5.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.6.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.7.5)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.1.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (3.0.28)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (2.6.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (3.5.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (1.0.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (4.10.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp<2,>=1.8.5->tfx[kfp]<2) (4.11.2)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp<2,>=1.8.5->tfx[kfp]<2) (0.18.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (2.10)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx[kfp]<2) (3.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (5.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.8.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp<2,>=1.8.5->tfx[kfp]<2) (3.7.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (4.9.2)\n",
            "Requirement already satisfied: typing-utils>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from overrides<7.0.0,>=6.0.1->google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.35->tfx[kfp]<2) (0.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner<2,>=1.0.4->tfx[kfp]<2) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (0.13.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (22.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.38,>=0.37.0->tfx[kfp]<2) (0.5.1)\n",
            "Installing collected packages: keras, tensorflow-metadata, tensorflow, tensorflow-serving-api, tfx-bsl, tensorflow-transform\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.7.0\n",
            "    Uninstalling tensorflow-metadata-1.7.0:\n",
            "      Successfully uninstalled tensorflow-metadata-1.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "  Attempting uninstall: tensorflow-serving-api\n",
            "    Found existing installation: tensorflow-serving-api 2.8.0\n",
            "    Uninstalling tensorflow-serving-api-2.8.0:\n",
            "      Successfully uninstalled tensorflow-serving-api-2.8.0\n",
            "  Attempting uninstall: tfx-bsl\n",
            "    Found existing installation: tfx-bsl 1.7.0\n",
            "    Uninstalling tfx-bsl-1.7.0:\n",
            "      Successfully uninstalled tfx-bsl-1.7.0\n",
            "  Attempting uninstall: tensorflow-transform\n",
            "    Found existing installation: tensorflow-transform 1.7.0\n",
            "    Uninstalling tensorflow-transform-1.7.0:\n",
            "      Successfully uninstalled tensorflow-transform-1.7.0\n",
            "Successfully installed keras-2.7.0 tensorflow-2.7.1 tensorflow-metadata-1.6.0 tensorflow-serving-api-2.7.0 tensorflow-transform-1.6.0 tfx-bsl-1.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow_transform in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Collecting tensorflow_transform\n",
            "  Using cached tensorflow_transform-1.7.0-py3-none-any.whl (433 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_transform) (1.3.0)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow_transform) (1.0.0)\n",
            "Collecting tensorflow-metadata<1.8.0,>=1.7.0\n",
            "  Using cached tensorflow_metadata-1.7.0-py3-none-any.whl (48 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.7/dist-packages (from tensorflow_transform) (1.21.5)\n",
            "Collecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5\n",
            "  Using cached tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.36 in /usr/local/lib/python3.7/dist-packages (from tensorflow_transform) (2.37.0)\n",
            "Requirement already satisfied: pyarrow<6,>=1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_transform) (5.0.0)\n",
            "Collecting tfx-bsl<1.8.0,>=1.7.0\n",
            "  Using cached tfx_bsl-1.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (19.2 MB)\n",
            "Requirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.7/dist-packages (from tensorflow_transform) (3.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py<2.0.0,>=0.9->tensorflow_transform) (1.15.0)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.17.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (3.10.0.2)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.3.1.1)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (3.6.7)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.44.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.27.1)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.20.3)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.4.10)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.7)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2021.3)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.0.0)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (3.12.3)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (4.1.3)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.6.0)\n",
            "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.35.0)\n",
            "Requirement already satisfied: grpcio-gcp<1,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.2.2)\n",
            "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.4.1)\n",
            "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.5.31)\n",
            "Requirement already satisfied: google-cloud-spanner<2,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.19.1)\n",
            "Requirement already satisfied: cachetools<5,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (4.2.4)\n",
            "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.8.0)\n",
            "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.0.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage>=2.6.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.12.0)\n",
            "Requirement already satisfied: google-cloud-recommendations-ai<=0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.2.0)\n",
            "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.7.2)\n",
            "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.3.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<3,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.34.2)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.10.0)\n",
            "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.16.1)\n",
            "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.36->tensorflow_transform) (3.6.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot<2,>=1.2->tensorflow_transform) (3.0.7)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (13.0.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.13.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (0.24.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata<1.8.0,>=1.7.0->tensorflow_transform) (1.55.0)\n",
            "Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.7/dist-packages (from tfx-bsl<1.8.0,>=1.7.0->tensorflow_transform) (1.3.5)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /usr/local/lib/python3.7/dist-packages (from tfx-bsl<1.8.0,>=1.7.0->tensorflow_transform) (1.12.10)\n",
            "Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3,>=1.15\n",
            "  Using cached tensorflow_serving_api-2.8.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (0.37.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.8.0,>=1.7.0->tensorflow_transform) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.8.0,>=1.7.0->tensorflow_transform) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.8.0,>=1.7.0->tensorflow_transform) (1.31.5)\n",
            "Requirement already satisfied: fasteners>=0.14 in /usr/local/lib/python3.7/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (4.8)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (20.9)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.3.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.12.3)\n",
            "Requirement already satisfied: grpcio-status>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.44.0)\n",
            "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (6.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.5.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.6.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.24.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (4.11.2)\n",
            "Requirement already satisfied: typing-utils>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from overrides<7.0.0,>=6.0.1->google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.36->tensorflow_transform) (0.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5->tensorflow_transform) (3.2.0)\n",
            "Installing collected packages: keras, tensorflow-metadata, tensorflow, tensorflow-serving-api, tfx-bsl, tensorflow_transform\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.6.0\n",
            "    Uninstalling tensorflow-metadata-1.6.0:\n",
            "      Successfully uninstalled tensorflow-metadata-1.6.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.1\n",
            "    Uninstalling tensorflow-2.7.1:\n",
            "      Successfully uninstalled tensorflow-2.7.1\n",
            "  Attempting uninstall: tensorflow-serving-api\n",
            "    Found existing installation: tensorflow-serving-api 2.7.0\n",
            "    Uninstalling tensorflow-serving-api-2.7.0:\n",
            "      Successfully uninstalled tensorflow-serving-api-2.7.0\n",
            "  Attempting uninstall: tfx-bsl\n",
            "    Found existing installation: tfx-bsl 1.6.0\n",
            "    Uninstalling tfx-bsl-1.6.0:\n",
            "      Successfully uninstalled tfx-bsl-1.6.0\n",
            "  Attempting uninstall: tensorflow_transform\n",
            "    Found existing installation: tensorflow-transform 1.6.0\n",
            "    Uninstalling tensorflow-transform-1.6.0:\n",
            "      Successfully uninstalled tensorflow-transform-1.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tfx 1.6.1 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5, but you have tensorflow 2.8.0 which is incompatible.\n",
            "tfx 1.6.1 requires tensorflow-transform<1.7.0,>=1.6.0, but you have tensorflow-transform 1.7.0 which is incompatible.\n",
            "tfx 1.6.1 requires tfx-bsl<1.7.0,>=1.6.0, but you have tfx-bsl 1.7.0 which is incompatible.\n",
            "tensorflow-model-analysis 0.37.0 requires tensorflow-metadata<1.7.0,>=1.6.0, but you have tensorflow-metadata 1.7.0 which is incompatible.\n",
            "tensorflow-model-analysis 0.37.0 requires tfx-bsl<1.7.0,>=1.6.0, but you have tfx-bsl 1.7.0 which is incompatible.\n",
            "tensorflow-data-validation 1.6.0 requires tensorflow-metadata<1.7,>=1.6.0, but you have tensorflow-metadata 1.7.0 which is incompatible.\n",
            "tensorflow-data-validation 1.6.0 requires tfx-bsl<1.7,>=1.6.0, but you have tfx-bsl 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.8.0 tensorflow-2.8.0 tensorflow-metadata-1.7.0 tensorflow-serving-api-2.8.0 tensorflow_transform-1.7.0 tfx-bsl-1.7.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Use the latest version of pip.\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade \"tfx[kfp]<2\"\n",
        "!pip install --upgrade tensorflow_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwT0nov5QO1M"
      },
      "source": [
        "### Restart the Runtime\n",
        "You will need to restart the runtime for the libraries to be available in Google Collab. Runtime > Restart Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gckGHdW9iPrq"
      },
      "source": [
        "### Login in to Google for this *notebook*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZQA0KrfXCvU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_SveIKxaENu"
      },
      "source": [
        "### Check the package versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-iP9wEaENu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4582eaeb-e6a1-46a5-ca31-ada3a64359c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n",
            "TFX version: 1.6.1\n",
            "KFP version: 1.8.11\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "from tfx import v1 as tfx\n",
        "print('TFX version: {}'.format(tfx.__version__))\n",
        "import kfp\n",
        "print('KFP version: {}'.format(kfp.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "### Set up variables\n",
        "\n",
        "We will set up some variables used to customize the pipelines below. Following\n",
        "information is required:\n",
        "\n",
        "* GCP Project id.\n",
        "* GCP Region to run pipelines.\n",
        "* Google Cloud Storage Bucket to store pipeline outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcUseqJaE2XN"
      },
      "outputs": [],
      "source": [
        "GOOGLE_CLOUD_PROJECT = 'ml-spec-demo-2-sandbox'\n",
        "GOOGLE_CLOUD_REGION = 'australia-southeast1'\n",
        "GCS_BUCKET_NAME = 'black_friday_gcp_bucket'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAaCPLjgiJrO"
      },
      "source": [
        "#### Set `gcloud` to use your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkWdxe4TXRHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd93c29f-9870-45da-eab2-7180b8b01eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        " {GOOGLE_CLOUD_PROJECT}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up Global variables for model serving locations"
      ],
      "metadata": {
        "id": "l_x_8xoj6k0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPN6UL5CazNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75956013-1a23-4e03-9162-99b0709e2dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIPELINE_ROOT: gs://black_friday_gcp_bucket/pipeline_root/black-friday-gcp-vertex-pipelines\n",
            "Data root: gs://black_friday_gcp_bucket/data/black-friday-gcp-vertex-pipelines\n"
          ]
        }
      ],
      "source": [
        "PIPELINE_NAME = 'black-friday-gcp-vertex-pipelines'\n",
        "\n",
        "# Path to pipeline artifacts\n",
        "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(\n",
        "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Paths for users' Python module\n",
        "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(\n",
        "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# Paths to training data\n",
        "DATA_ROOT = 'gs://{}/data/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "# This is the path where your model will be pushed for serving\n",
        "SERVING_MODEL_DIR = 'gs://{}/serving_model/{}'.format(\n",
        "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
        "\n",
        "\n",
        "# Training data file name\n",
        "FILE_NAME = 'train.csv'\n",
        "\n",
        "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))\n",
        "print('Data root: {}'.format(DATA_ROOT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11J7XiCq6AFP"
      },
      "source": [
        "We need to make our own copy of the dataset. Because TFX ExampleGen reads\n",
        "inputs from a directory, we need to create a directory and copy dataset to it\n",
        "on GCS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASpoNmxKSQjI"
      },
      "source": [
        "Take a quick look at the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eSz28UDSnlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509dfedd-6c1e-4017-a2f4-8e5caa9dd254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User_ID,Product_ID,Gender,Age,Occupation,City_Category,Stay_In_Current_City_Years,Marital_Status,Product_Category_1,Product_Category_2,Product_Category_3,Purchase\r\n",
            "1000001,P00069042,F,0-17,10,A,2,0,3,,,8370\r\n",
            "1000001,P00248942,F,0-17,10,A,2,0,1,6,14,15200\r\n",
            "1000001,P00087842,F,0-17,10,A,2,0,12,,,1422\r\n",
            "1000001,P00085442,F,0-17,10,A,2,0,12,14,,1057\r\n",
            "1000002,P00285442,M,55+,16,C,4+,0,8,,,7969\r\n",
            "1000003,P00193542,M,26-35,15,A,3,0,1,2,,15227\r\n",
            "1000004,P00184942,M,46-50,7,B,2,1,1,8,17,19215\r\n",
            "1000004,P00346142,M,46-50,7,B,2,1,1,15,,15854\r\n",
            "1000004,P0097242,M,46-50,7,B,2,1,1,16,,15686\r\n"
          ]
        }
      ],
      "source": [
        "!gsutil cat {DATA_ROOT}/train.csv | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH6gizcpSwWV"
      },
      "source": [
        "## Create a pipeline\n",
        "\n",
        "TFX pipelines are defined using Python APIs. We will define a pipeline which\n",
        "consists of three components, CsvExampleGen, Trainer and Pusher. The pipeline\n",
        "and model definition is almost the same as\n",
        "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
        "\n",
        "The only difference is that we don't need to set `metadata_connection_config`\n",
        "which is used to locate\n",
        "[ML Metadata](https://www.tensorflow.org/tfx/guide/mlmd) database. Because\n",
        "Vertex Pipelines uses a managed metadata service, users don't need to care\n",
        "of it, and we don't need to specify the parameter.\n",
        "\n",
        "Before actually define the pipeline, we need to write a model code for the\n",
        "Trainer component first."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write Example Component\n"
      ],
      "metadata": {
        "id": "VyBh_2LO4Ccw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### Write model code.\n",
        "\n",
        "We will use the same model code as in the\n",
        "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aES7Hv5QTDK3"
      },
      "outputs": [],
      "source": [
        "_trainer_module_file = 'bfs_trainer.py'\n",
        "_transformer_module_file = 'transformer.py'\n",
        "_training_pipeline_file = 'training_pipeline.py'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {_transformer_module_file}\n",
        "\n",
        "from typing import Dict, Text, Any, List\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "FEATURES = [\n",
        "            'Product_ID',\n",
        "            'Gender',\n",
        "            'Age',\n",
        "            'Occupation',\n",
        "            'City_Category', \n",
        "            'Stay_In_Current_City_Years',\n",
        "            'Marital_Status',\n",
        "            'Product_Category_1',\n",
        "            'Product_Category_2',\n",
        "            'Purchase'\n",
        "            ]\n",
        "\n",
        "CATEGORICAL_FEATURE_KEYS = [\n",
        "                            'Product_ID', \n",
        "                            'Age', \n",
        "                            'City_Category', \n",
        "                            'Product_Category_1', \n",
        "                            'Product_Category_2', \n",
        "                            'Stay_In_Current_City_Years',\n",
        "                            'Gender'\n",
        "                            ]\n",
        "\n",
        "OPTIONAL_NUMERIC_KEY_FEATURES = ['Product_Category_2']\n",
        "\n",
        "def preprocessing_fn(inputs: Dict[Text, Any], custom_config) -> Dict[Text, Any]:\n",
        "    \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "    Args:\n",
        "      inputs: map from feature keys to raw not-yet-transformed features.\n",
        "      custom_config:\n",
        "        timesteps: The number of timesteps in the look back window\n",
        "        features: Which of the features from the TF.Example to use in the model.\n",
        "    Returns:\n",
        "      Map from string feature key to transformed feature operations.\n",
        "    \"\"\"\n",
        "    print('Start preprocessing')\n",
        "    outputs = {}\n",
        "    for key in FEATURES:\n",
        "      key_l = key.lower()\n",
        "      outputs[key_l] = inputs[key]\n",
        "\n",
        "\n",
        "    # Convert optional categories to sparse tensor (fills in blank values basically)\n",
        "    for key in OPTIONAL_NUMERIC_KEY_FEATURES:\n",
        "      key_l = key.lower()\n",
        "      sparse = tf.sparse.SparseTensor(inputs[key].indices, inputs[key].values,\n",
        "                                      [inputs[key].dense_shape[0], 1])\n",
        "      dense = tf.sparse.to_dense(sp_input=sparse, default_value=0)\n",
        "\n",
        "      # Reshaping from a batch of vectors of size 1 to a batch to scalars.\n",
        "      dense = tf.squeeze(dense, axis=1)\n",
        "      outputs[key_l] = dense\n",
        "\n",
        "    for key in CATEGORICAL_FEATURE_KEYS:\n",
        "      key_l = key.lower()\n",
        "      outputs[key_l] = tft.compute_and_apply_vocabulary(inputs[key])\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "OB3fD-DSuAJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef1dc42-31f1-4081-dd9a-0910c8208ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing transformer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnc67uQNTDfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46575526-ccab-4867-b7c5-85b85e49d8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting bfs_trainer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "from tensorflow.keras import layers\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "\n",
        "import tensorflow_transform as tft\n",
        "from tfx.components.example_gen import utils as example_gen_utils\n",
        "\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "FEATURES = [\n",
        "            'product_id',\n",
        "            'gender',\n",
        "            'age', \n",
        "            'occupation', \n",
        "            'city_category', \n",
        "            'stay_in_current_city_years', \n",
        "            'marital_status', \n",
        "            'product_category_1',\n",
        "            'product_category_2'\n",
        "            ]\n",
        "\n",
        "LABEL = 'purchase'\n",
        "\n",
        "# NEW: This function will create a handler function which gets a serialized\n",
        "#      tf.example, preprocess and run an inference with it.\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "  # We must save the tft_layer to the model to ensure its assets are kept and\n",
        "  # tracked.\n",
        "  model.tft_layer_inference = tf_transform_output.transform_features_layer()\n",
        "\n",
        "  @tf.function(input_signature=[\n",
        "      tf.TensorSpec(shape=[None], dtype=tf.string, name='examples')\n",
        "  ])\n",
        "  def serve_tf_examples_fn(serialized_tf_examples):\n",
        "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "    # raw_feature_spec = tf_transform_output.raw_feature_spec()\n",
        "    # Remove label feature since these will not be present at serving time.\n",
        "    # raw_feature_spec.pop(LABEL)\n",
        "    # logging.info(f\"Raw_Feature_Spec: {raw_feature_spec}\")\n",
        "    # raw_features = tf.io.parse_example(serialized_tf_examples, raw_feature_spec)\n",
        "    #json_dict = json.loads(raw_features) # json to dict\n",
        "    #parsed_features = example_gen_utils.dict_to_example(json_dict) # TFX contains a utility fn for converting a dict to (unserialized) tf Example \n",
        "    #transformed_features = model.tft_layer_inference(parsed_features)\n",
        "    feature_spec = tf_transform_output.raw_feature_spec()\n",
        "    feature_spec.pop(\"Purchase\")\n",
        "    feature_spec.pop(\"User_ID\")\n",
        "    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "    transformed_features = model.tft_layer_inference(parsed_features)\n",
        "    outputs = model(transformed_features)\n",
        "    return {'outputs': outputs}\n",
        "\n",
        "  return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "def _make_keras_model() -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model.\n",
        "  \"\"\"\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in FEATURES]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  d = keras.layers.Dense(128, activation='relu')(d)\n",
        "  d = keras.layers.Dense(256, activation='relu')(d)\n",
        "  d = keras.layers.Dense(128, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(1)(d)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=tf.optimizers.Adam(learning_rate=0.0005), \n",
        "      loss=tf.keras.losses.MeanSquaredError(),\n",
        "      metrics=[keras.metrics.MeanSquaredError()]\n",
        "    )\n",
        "  \n",
        "  model.summary(print_fn=logging.info)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
        "  # version provided by pipeline author. A schema can also derived from TFT\n",
        "  # graph if a Transform component is used. In the case when either is missing,\n",
        "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
        "  # feature_spec, but the schema returned would be very primitive.\n",
        "  \n",
        "  # get transform component output\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "  # read input data\n",
        "  train_dataset = fn_args.data_accessor.tf_dataset_factory(\n",
        "      fn_args.train_files,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=20,\n",
        "          label_key=LABEL\n",
        "      ),\n",
        "      tf_transform_output.transformed_metadata.schema,\n",
        "  )\n",
        "\n",
        "  eval_dataset = fn_args.data_accessor.tf_dataset_factory(\n",
        "      fn_args.eval_files,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=10,\n",
        "          label_key=LABEL\n",
        "      ),\n",
        "      tf_transform_output.transformed_metadata.schema,\n",
        "  )\n",
        "\n",
        "  model = _make_keras_model()\n",
        "\n",
        "\n",
        "  # Train model\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps\n",
        "  )\n",
        "\n",
        "  # The layer has to be saved to the model for keras tracking purpases.\n",
        "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "  \n",
        "  signatures = {\n",
        "      'serving_default': _get_serve_tf_examples_fn(model, tf_transform_output)\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy files to bucket\n",
        "The transform and trainer module files need to be copied over to the GCP bucket for TFX to read."
      ],
      "metadata": {
        "id": "-j54Ya94tR1-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMMs5wuNYAbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d120a9c3-c107-47d2-bf8a-961f62f1502f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://bfs_trainer.py [Content-Type=text/x-python]...\n",
            "/ [1 files][  4.8 KiB/  4.8 KiB]                                                \n",
            "Operation completed over 1 objects/4.8 KiB.                                      \n",
            "Copying file://transformer.py [Content-Type=text/x-python]...\n",
            "-\n",
            "Operation completed over 1 objects/2.1 KiB.                                      \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp {_trainer_module_file} {MODULE_ROOT}/\n",
        "!gsutil cp {_transformer_module_file} {MODULE_ROOT}/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create TFX pipeline. This pipeline can then be passed onto an orchestrator, such as KubeFlow, for deployment."
      ],
      "metadata": {
        "id": "q-3jxJZcI7q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "from tensorflow.keras import layers\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "from tfx.orchestration.pipeline import Pipeline\n",
        "from tfx.proto.trainer_pb2 import EvalArgs, TrainArgs\n",
        "\n",
        "# docs_infra: no_execute\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "\n",
        "def build_pipeline(pipeline_name, pipeline_root, serving_model_dir, data_root, file_name):\n",
        "  print(\"Running pipeline\")\n",
        "\n",
        "  print(\"Creating example_gen\")\n",
        "  # Generate Training Samples from Dataset stored on bucket.\n",
        "  example_gen = tfx.components.CsvExampleGen(\n",
        "    input_base=data_root\n",
        "  )\n",
        "\n",
        "  print(\"Creating statistics_gen\")\n",
        "  # Generate statistics over data for visualization and example validation.\n",
        "  statistics_gen = tfx.components.StatisticsGen(\n",
        "      examples=example_gen.outputs[\"examples\"]\n",
        "  )\n",
        "\n",
        "  print(\"Creating schema_gen\")\n",
        "  # Generates schema based on statistic files\n",
        "  schema_gen = tfx.components.SchemaGen(\n",
        "      statistics=statistics_gen.outputs[\"statistics\"],\n",
        "      #infer_feature_shape=True  \n",
        "  )\n",
        "\n",
        "  print(\"Creating example_validator\")\n",
        "  # Performs anomaly dection based on statistics and data schema\n",
        "  example_validator = tfx.components.ExampleValidator(\n",
        "      statistics=statistics_gen.outputs[\"statistics\"],\n",
        "      schema=schema_gen.outputs[\"schema\"]\n",
        "  )\n",
        "\n",
        "  print(\"Creating transform\")\n",
        "  transform = tfx.components.Transform(\n",
        "      examples=example_gen.outputs[\"examples\"],\n",
        "      schema=schema_gen.outputs[\"schema\"],\n",
        "      module_file=os.path.join(MODULE_ROOT, _transformer_module_file)\n",
        "  )\n",
        "\n",
        "  print(\"Creating trainer\")\n",
        "  # Trains the model\n",
        "  trainer = tfx.components.Trainer(\n",
        "      examples=transform.outputs[\"transformed_examples\"],\n",
        "      transform_graph=transform.outputs[\"transform_graph\"],\n",
        "      module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
        "      schema=schema_gen.outputs[\"schema\"],\n",
        "      train_args=TrainArgs(num_steps=150),\n",
        "      eval_args=EvalArgs(num_steps=150)\n",
        "\n",
        "  )\n",
        "\n",
        "  print(\"Creating pusher\")\n",
        "  # Pushes the trained model to vertex\n",
        "  pusher = tfx.components.Pusher(\n",
        "      trainer.outputs['model'],\n",
        "      push_destination=tfx.proto.PushDestination(\n",
        "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir)),\n",
        "  )\n",
        "  \n",
        "  print(\"Creating tfx_pipeline\")\n",
        "  tfx_pipeline = Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      components=[\n",
        "          example_gen,\n",
        "          statistics_gen,\n",
        "          schema_gen,\n",
        "          example_validator,\n",
        "          transform,\n",
        "          trainer,\n",
        "          pusher\n",
        "      ],\n",
        "      data_root=data_root,\n",
        "      module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
        "      serving_model_dir=serving_model_dir,\n",
        "      enable_cache=False\n",
        "  )\n",
        "\n",
        "\n",
        "  pipeline_definition_file = pipeline_name + '_pipeline.json'\n",
        "\n",
        "  print(\"Creating runner\")\n",
        "  runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
        "      config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
        "      output_filename=pipeline_definition_file)\n",
        "  \n",
        "\n",
        "  print(\"Executing runner\")\n",
        "  # Following function will write the pipeline definition to PIPELINE_DEFINITION_FILE.\n",
        "  _ = runner.run(tfx_pipeline)\n",
        "\n",
        "\n",
        "def deploy_to_vertex(pipeline_name, project_name, cloud_region):\n",
        "  aiplatform.init(project=project_name, location=cloud_region)\n",
        "  pipeline_definition_file = pipeline_name + '_pipeline.json'\n",
        "  job = pipeline_jobs.PipelineJob(template_path=pipeline_definition_file,\n",
        "                                display_name=pipeline_name)\n",
        "  job.run(sync=False)\n",
        "\n",
        "build_pipeline(PIPELINE_NAME, PIPELINE_ROOT, SERVING_MODEL_DIR, DATA_ROOT, FILE_NAME)"
      ],
      "metadata": {
        "id": "jPiXvdhXvkGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb91161-5bef-4fec-c5a8-de4340fe7ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running pipeline\n",
            "Creating example_gen\n",
            "Creating statistics_gen\n",
            "Creating schema_gen\n",
            "Creating example_validator\n",
            "Creating transform\n",
            "Creating trainer\n",
            "Creating pusher\n",
            "Creating tfx_pipeline\n",
            "Creating runner\n",
            "Executing runner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Pipeline to Vertex AI\n",
        "TFX can be deployed to Vertex AI. The build_pipeline function deploys the pipeline to using the Kubeflow V2 orchestrator."
      ],
      "metadata": {
        "id": "98QiNea9XtrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deploy_to_vertex(PIPELINE_NAME, GOOGLE_CLOUD_PROJECT, GOOGLE_CLOUD_REGION)"
      ],
      "metadata": {
        "id": "S9g9yOH5wQfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e255fa2-9987-4926-e339-56835167160f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Accuracy\n",
        "You can check the model accuracy by reading the logs outputted by trainer module in Vertex AI. The accuracy seems to match the Neural Networks done in the exploration phase coming in with a RME of 80,064,008."
      ],
      "metadata": {
        "id": "Z8dyPhVZJj_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up Vertex AI Endpoints\n",
        "\n",
        "Once the model is trained it is placed into the Google Bucket under: \n",
        "\n",
        "```\n",
        "black_friday_gcp_bucket/serving_model/black-friday-gcp-vertex-pipelines/#\n",
        "```\n",
        "\n",
        "This model will need to be registered in Vertex AI's Model service.\n",
        "\n",
        "Once this model has been setup, Vertex AI's endpoint service can easily be configured to point to the registered model."
      ],
      "metadata": {
        "id": "XTEkHdhEvBQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inferencing\n",
        "Once the endpoint has been set up it can be inferenced using a grpc request. \n",
        "\n",
        "To inference request's body structure is:\n",
        "\n",
        "```\n",
        "      {\"instances\": \n",
        "        [{\n",
        "          \"examples\": {\n",
        "            b64: \"<base64 encoded, serialized tensorflow example>\"\n",
        "          }\n",
        "        }]\n",
        "      }\n",
        "```\n",
        "\n",
        "\n",
        "This request can be done using the following client code."
      ],
      "metadata": {
        "id": "HF8iAToXQPLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GCP Endpoint ID\n",
        "ENDPOINT = \"6519734516804747264\""
      ],
      "metadata": {
        "id": "1fOecX2XHsYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.train.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_example(product_id, gender, age, occupation, city_category, stay_in_current_city_years, marital_status, product_category_1, product_category_2):\n",
        "  \"\"\"\n",
        "  Creates a tf.train.Example message ready to be written to a file.\n",
        "  \"\"\"\n",
        "  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
        "  # data type.\n",
        "  feature = {\n",
        "      'Product_ID': _bytes_feature(product_id),\n",
        "      'Gender': _bytes_feature(gender),\n",
        "      'Age': _bytes_feature(age),\n",
        "      'Occupation': _int64_feature(occupation),\n",
        "      'City_Category': _bytes_feature(city_category),\n",
        "      'Stay_In_Current_City_Years': _bytes_feature(stay_in_current_city_years),\n",
        "      'Marital_Status': _int64_feature(marital_status),\n",
        "      'Product_Category_1': _int64_feature(product_category_1),\n",
        "      'Product_Category_2': _int64_feature(product_category_2),\n",
        "  }\n",
        "\n",
        "  # Create a Features message using tf.train.Example.\n",
        "\n",
        "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  return example_proto.SerializeToString()"
      ],
      "metadata": {
        "id": "zO3vEf2iLlOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kQjNcCNuI2uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "packet = {\n",
        "    \"product_id\": b'P00069042',\n",
        "    \"gender\": b'F',\n",
        "    \"age\": b'0-17',\n",
        "    \"occupation\": 10,\n",
        "    \"city_category\": b'A',\n",
        "    \"stay_in_current_city_years\": b'2',\n",
        "    \"marital_status\": 0,\n",
        "    \"product_category_1\": 2,\n",
        "    \"product_category_2\": 6\n",
        "}\n",
        "\n",
        "serialized_example = serialize_example(**packet)\n",
        "print(f\"Serialized_example: {serialized_example}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WosjtWKLuAr",
        "outputId": "f9a0914d-e748-45c6-8471-d9a76ed1819b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serialized_example: b\"\\n\\x8c\\x02\\n\\x12\\n\\x07User_ID\\x12\\x07\\x1a\\x05\\n\\x03\\xc1\\x84=\\n\\x12\\n\\x08Purchase\\x12\\x06\\x1a\\x04\\n\\x02\\x88'\\n\\x0f\\n\\x03Age\\x12\\x08\\n\\x06\\n\\x040-17\\n\\x1b\\n\\nProduct_ID\\x12\\r\\n\\x0b\\n\\tP00069042\\n\\x1b\\n\\x12Product_Category_1\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n#\\n\\x1aStay_In_Current_City_Years\\x12\\x05\\n\\x03\\n\\x012\\n\\x1b\\n\\x12Product_Category_2\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n\\x16\\n\\rCity_Category\\x12\\x05\\n\\x03\\n\\x01A\\n\\x0f\\n\\x06Gender\\x12\\x05\\n\\x03\\n\\x01F\\n\\x13\\n\\nOccupation\\x12\\x05\\x1a\\x03\\n\\x01\\n\\n\\x17\\n\\x0eMarital_Status\\x12\\x05\\x1a\\x03\\n\\x01\\x00\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that the serialized example correctly parses back."
      ],
      "metadata": {
        "id": "2mV2g9wTHMHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "example_proto = tf.train.Example.FromString(serialized_example)\n",
        "example_proto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCkSMK3r2wjy",
        "outputId": "e93a6365-95e5-47c2-9a2e-ec7097409d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "features {\n",
              "  feature {\n",
              "    key: \"Age\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"0-17\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"City_Category\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"A\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Gender\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"F\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Marital_Status\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 0\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Occupation\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 10\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Product_Category_1\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 2\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Product_Category_2\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 6\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Product_ID\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"P00069042\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Purchase\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 5000\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"Stay_In_Current_City_Years\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"2\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"User_ID\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 1000001\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode packet into Base64, build packet and inference."
      ],
      "metadata": {
        "id": "wTrzJi2DHyLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "import base64\n",
        "\n",
        "b64_example = base64.b64encode(serialized_example).decode(\"utf-8\")\n",
        "print(f\"Base64 encoded example: {b64_example}\")\n",
        "instances_packet = [{\n",
        "  \"examples\": {\n",
        "    \"b64\": b64_example\n",
        "  }\n",
        "}]\n",
        "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location='australia-southeast1')\n",
        "endpoint = aiplatform.Endpoint(ENDPOINT)\n",
        "prediction = endpoint.predict(instances=instances_packet)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV2UH9G2HWj0",
        "outputId": "d56b52f6-ae17-4f52-d9a7-41d01dfd3239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base64 encoded example: CowCChIKB1VzZXJfSUQSBxoFCgPBhD0KEgoIUHVyY2hhc2USBhoECgKIJwoPCgNBZ2USCAoGCgQwLTE3ChsKClByb2R1Y3RfSUQSDQoLCglQMDAwNjkwNDIKGwoSUHJvZHVjdF9DYXRlZ29yeV8xEgUaAwoBAgojChpTdGF5X0luX0N1cnJlbnRfQ2l0eV9ZZWFycxIFCgMKATIKGwoSUHJvZHVjdF9DYXRlZ29yeV8yEgUaAwoBBgoWCg1DaXR5X0NhdGVnb3J5EgUKAwoBQQoPCgZHZW5kZXISBQoDCgFGChMKCk9jY3VwYXRpb24SBRoDCgEKChcKDk1hcml0YWxfU3RhdHVzEgUaAwoBAA==\n",
            "Prediction(predictions=[[4547.0752]], deployed_model_id='1053314547223363584', explanations=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloud Function\n",
        "To get an inference from the model a query needs to be made to the cloud function with the packet structure:\n",
        "\n",
        "```\n",
        "{\n",
        "  \"User_ID: 1000047 #A Valid User_ID (Int)\n",
        "}\n",
        "```\n",
        "\n",
        "The cloud function will then gather the top 10 Product_IDs the user is most_likely to buy, the User's profile, and Product Information before returning a summation of the Users expected spenditure for the month on these products.\n",
        "\n",
        "This code can be found in the \"Cloud Function\" folder under ``` main.py ```."
      ],
      "metadata": {
        "id": "mj_xUwkVU5Fl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Black Friday Sales pipeline using TFX",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}